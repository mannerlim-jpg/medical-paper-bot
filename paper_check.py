import requests
import datetime
import os
import xml.etree.ElementTree as ET
import re

# 1. ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë° ì˜ë£Œ í•„í„° ê°•í™”
CATEGORIES = {
    "ğŸ¤– ë¡œë´‡ ë³´ì¡° ìˆ˜ìˆ  (Robot-Assisted)": ["ROBOT ASSISTED", "SURGICAL ROBOT", "MAKO", "ROSA", "NAVIO"],
    "ğŸ¦¶ ë°œëª© ë° ì¡±ë¶€ (Ankle & Foot)": ["ANKLE ARTHROSCOPY", "TALAR", "ANKLE FRACTURE"],
    "ğŸ¦µ ë¬´ë¦ ë° ì¸ê³µê´€ì ˆ (Knee & TKR)": ["TKR", "TKA", "KNEE ARTHROSCOPY", "KNEE REPLACEMENT"]
}

# ë¡œë´‡ ê´€ë ¨ ë…¼ë¬¸ ì¤‘ ì˜ë£Œìš©ë§Œ ê³¨ë¼ë‚´ê¸° ìœ„í•œ í•„ìˆ˜ ë‹¨ì–´
MEDICAL_FILTER = ["SURGERY", "SURGICAL", "PATIENT", "CLINICAL", "ORTHOPEDIC", "KNEE", "ANKLE", "MEDICINE"]

def fetch_papers():
    today = datetime.date.today()
    seen_links = set()
    
    if os.path.exists("papers.md"):
        with open("papers.md", "r", encoding="utf-8") as f:
            seen_links = set(re.findall(r'https?://arxiv\.org/abs/\S+', f.read()))

    # ê²€ìƒ‰ ì¿¼ë¦¬: ì˜í•™ ê´€ë ¨ì„±ì´ ë†’ì€ ë…¼ë¬¸ë§Œ ê°€ì ¸ì˜¤ë„ë¡ í‚¤ì›Œë“œ ì¡°í•©
    all_search_terms = [k for v in CATEGORIES.values() for k in v]
    query = " OR ".join([f'all:"{k}"' for k in all_search_terms])
    url = f"https://export.arxiv.org/api/query?search_query={query}&sortOrder=descending&max_results=50"
    
    response = requests.get(url)
    root = ET.fromstring(response.text)
    
    classified_report = {cat: [] for cat in CATEGORIES.keys()}

    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):
        title = entry.find('{http://www.w3.org/2005/Atom}title').text.strip().replace('\n', ' ')
        # ë§í¬ë¥¼ httpì—ì„œ httpsë¡œ ê°•ì œ ë³€ê²½ (ì—°ê²°ì„± ê°•í™”)
        link = entry.find('{http://www.w3.org/2005/Atom}id').text.strip().replace('http://', 'https://')
        
        if link in seen_links: continue

        title_upper = title.upper()
        
        # ì¹´í…Œê³ ë¦¬ ë°°ì • ë° í•„í„°ë§
        for cat, keywords in CATEGORIES.items():
            if any(k in title_upper for k in keywords):
                # ë¡œë´‡ ì¹´í…Œê³ ë¦¬ì˜ ê²½ìš° ì˜ë£Œ ê´€ë ¨ ë‹¨ì–´ê°€ ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•¨
                if "ğŸ¤–" in cat:
                    if not any(mf in title_upper for mf in MEDICAL_FILTER):
                        continue
                
                # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ë‹´ê¸°
                if len(classified_report[cat]) < 5:
                    classified_report[cat].append({"title": title, "link": link})
                break
        
    has_new_content = any(len(papers) > 0 for papers in classified_report.values())

    if has_new_content:
        with open("papers.md", "a", encoding="utf-8") as f:
            f.write(f"\n\n## ğŸ“… {today} ì‹ ê·œ ë…¼ë¬¸ ë¸Œë¦¬í•‘\n")
            for cat, papers in classified_report.items():
                if papers:
                    f.write(f"\n### {cat}\n")
                    for p in papers:
                        # êµ¬ê¸€ì±—ì—ì„œ í´ë¦­í•˜ê¸° ê°€ì¥ í¸í•œ í˜•íƒœë¡œ ë§í¬ ì œê³µ
                        f.write(f"* **ì œëª©:** {p['title']}\n  * **ì›ë¬¸ë§í¬:** <{p['link']}>\n")
        print("í•„í„°ë§ ë° ë¶„ë¥˜ ì™„ë£Œ!")
    else:
        print("ìƒˆë¡œ ì¶”ê°€í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    fetch_papers()
