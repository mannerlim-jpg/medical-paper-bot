import requests
import datetime
import os
import xml.etree.ElementTree as ET

# ê²€ìƒ‰í•  í‚¤ì›Œë“œ ëª©ë¡
KEYWORDS = ["TKR", "Robot assisted TKR", "Knee arthroscopy", "Ankle arthroscopy"]

def fetch_papers():
    today = datetime.date.today()
    # 1. ê¸°ì¡´ì— ë³´ê³ í–ˆë˜ ë…¼ë¬¸ ë§í¬ë“¤ì„ ì½ì–´ì˜µë‹ˆë‹¤.
    seen_links = set()
    if os.path.exists("papers.md"):
        with open("papers.md", "r", encoding="utf-8") as f:
            content = f.read()
            # íŒŒì¼ ë‚´ìš© ì¤‘ httpë¡œ ì‹œì‘í•˜ëŠ” ë§í¬ë“¤ì„ ì°¾ì•„ ëª©ë¡ì— ë„£ìŠµë‹ˆë‹¤.
            import re
            links = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', content)
            seen_links = set(links)

    # 2. arXiv APIë¡œ ìµœì‹  ë…¼ë¬¸ ê²€ìƒ‰
    base_url = "http://export.arxiv.org/api/query?search_query="
    query = " OR ".join([f'all:"{k}"' for k in KEYWORDS])
    url = base_url + query + "&sortOrder=descending&max_results=20" # ê²€ìƒ‰ ë²”ìœ„ë¥¼ ì¡°ê¸ˆ ëŠ˜ë ¸ìŠµë‹ˆë‹¤.
    
    response = requests.get(url)
    root = ET.fromstring(response.text)
    
    new_papers = []
    
    # 3. ìƒˆë¡œ ì°¾ì€ ë…¼ë¬¸ ì¤‘ ì¤‘ë³µë˜ì§€ ì•Šì€ ê²ƒë§Œ ê³¨ë¼ëƒ…ë‹ˆë‹¤.
    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):
        title = entry.find('{http://www.w3.org/2005/Atom}title').text.strip().replace('\n', ' ')
        link = entry.find('{http://www.w3.org/2005/Atom}id').text.strip()
        
        # 'ì€í•˜ê³„(Galaxy)' ê°™ì€ ì—‰ëš±í•œ í‚¤ì›Œë“œê°€ ì„ì´ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ë³´ì¡° ì¥ì¹˜
        # ì œëª©ì— í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        title_upper = title.upper()
        if not any(k.upper() in title_upper for k in KEYWORDS):
            continue

        # ì´ë¯¸ ë³´ë‚¸ ë§í¬ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì €ì¥ ëª©ë¡ì— ì¶”ê°€
        if link not in seen_links:
            new_papers.append({"title": title, "link": link})

    # 4. ê²°ê³¼ ê¸°ë¡ (ì¤‘ë³µì´ ì—†ëŠ” ê²½ìš°ë§Œ íŒŒì¼ì— ì¶”ê°€)
    if new_papers:
        with open("papers.md", "a", encoding="utf-8") as f:
            f.write(f"\n\n### ğŸ“… {today} ì‹ ê·œ ë…¼ë¬¸ ì•Œë¦¼\n")
            for paper in new_papers:
                f.write(f"* **ì œëª©:** {paper['title']}\n  * **ë§í¬:** {paper['link']}\n")
        print(f"{len(new_papers)}ê°œì˜ ìƒˆë¡œìš´ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    else:
        print("ìƒˆë¡œ ì¶”ê°€í•  ì¤‘ë³µë˜ì§€ ì•Šì€ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    fetch_papers()
